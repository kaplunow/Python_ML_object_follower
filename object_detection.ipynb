{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "delayed-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839de4987ccc4a5794b6088df861d009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'', format='jpeg', height='224', width='224'),)),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()\n",
    "    \n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "segment_dims = (74, 223)\n",
    "\n",
    "def create_segments(frame, dims, overlap):\n",
    "    width = dims[0]\n",
    "    height = dims[1]\n",
    "    rows, columns, channels = frame.shape\n",
    "    coords_vec = []\n",
    "    frames_vec = []\n",
    "    for i in range(0, rows-height, height-overlap):\n",
    "        for j in range(0, columns-width, width-overlap):\n",
    "            sub_frame = frame[i:(i+height), j:(j + width)]\n",
    "            coords_vec.append((i, j))\n",
    "            frames_vec.append(sub_frame)\n",
    "    return coords_vec, frames_vec\n",
    "\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x\n",
    "\n",
    "\n",
    "def draw_bounding_boxes(frame, draw_list, sub_coords):\n",
    "    global segment_dims\n",
    "    # 0 - height\n",
    "    for i in draw_list:\n",
    "        cv2.rectangle(frame, (sub_coords[i][1], sub_coords[i][0]), (segment_dims[0]+sub_coords[i][1], segment_dims[1]+sub_coords[i][1]), (0, 255, 255), 2)\n",
    "    return frame\n",
    "    \n",
    "    \n",
    "def get_draw_list(frame):\n",
    "    sub_coords, sub_frames = create_segments(frame, segment_dims, 0)\n",
    "    i = 0\n",
    "    draw_list = []\n",
    "    for sub_f in sub_frames:\n",
    "        frame_proc = preprocess(cv2.resize(sub_f, (224, 224)))\n",
    "        y = model(frame_proc)\n",
    "        y = F.softmax(y, dim=1)\n",
    "        prob = float(y.flatten()[0])\n",
    "        if prob > 0.5:\n",
    "            draw_list.append(i)\n",
    "        i += 1\n",
    "    return draw_list, sub_coords\n",
    "        \n",
    "\n",
    "def robot_update(draw_list):\n",
    "    global robot\n",
    "    if len(draw_list) == 1:\n",
    "        if draw_list[0] == 0:\n",
    "            robot.left(0.3)\n",
    "        elif draw_list[0] ==1:\n",
    "            robot.forward(0.3)\n",
    "        elif draw_list[0] == 2:\n",
    "            robot.right(0.3)\n",
    "    elif len(draw_list) == 2:\n",
    "        if draw_list[0] == 1:\n",
    "            robot.left(0.3)\n",
    "        else:\n",
    "            robot.right(0.3)\n",
    "    \n",
    "    else:\n",
    "        robot.stop()\n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "def update(change):\n",
    "    global person_slider, horse_slider, nothing_slider, image\n",
    "    x = change['new']\n",
    "    frame = x\n",
    "\n",
    "    draw_list, sub_coords = get_draw_list(frame)\n",
    "    frame = draw_bounding_boxes(frame, draw_list, sub_coords)\n",
    "    robot_update(draw_list)\n",
    "    image.value = bgr8_to_jpeg(frame)\n",
    "   # time.sleep(0.001)\n",
    "\n",
    "    \n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 3)\n",
    "model.load_state_dict(torch.load('best_model_laptop_farm.pth'))\n",
    "model.eval()\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)  # place model on GPU\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([image])]))\n",
    "\n",
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera\n",
    "update({'new': camera.value})  # we call the function once to initialize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_update(draw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "camera.stop()\n",
    "print(\"app stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-destiny",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-military",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
